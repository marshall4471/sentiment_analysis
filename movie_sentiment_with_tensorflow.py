# -*- coding: utf-8 -*-
"""movie_sentiment_with_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qi8icVOLmP-7Pr2SqoDjQkW6EEW84C9V
"""

import numpy as np

import shutil

import tensorflow_hub as hub

import tensorflow as tf

import tensorflow_datasets as tfds

train_data, test_data = tfds.load(name="imdb_reviews", split=["train", "test"], as_supervised=True)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

training_sentences=[]
training_labels=[]
testing_sentences=[]
testing_labels=[]
for sentence,label in train_data:
    training_sentences.append(str(sentence.numpy()))
    training_labels.append(label.numpy())
for sentence,label in test_data:
    testing_sentences.append(str(sentence.numpy()))
    testing_labels.append(label.numpy())
training_labels_final=np.array(training_labels)
testing_labels_final=np.array(testing_labels)

vocab_size=10000
embedding_dim = 16
max_length = 120
trunc_type='post'
oov_tok = "<OOV>"

tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(training_sentences)
word_index = tokenizer.word_index

training_sequences=tokenizer.texts_to_sequences(training_sentences)
testing_sequences=tokenizer.texts_to_sequences(testing_sentences)

training_padded=pad_sequences(training_sequences,maxlen=max_length,truncating=trunc_type)
testing_padded=pad_sequences(testing_sequences, maxlen=max_length,truncating=trunc_type)

model = tf.keras.Sequential([
                    tf.keras.layers.Embedding(vocab_size,    embedding_dim, input_length=max_length),
                    tf.keras.layers.Flatten(),
                    tf.keras.layers.Dense(6, activation='relu'),
                    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(training_padded, training_labels_final, epochs=12, validation_data=(testing_padded, testing_labels_final))

review_pred = ['I really liked this movie. But there where a few scenes in the movie that were annoying',
               'I hated this movie. But atleast the actor in the movie I cant stand lost',
               'This movie was awesome. They really need to make a sequel',
               'This movie really seemed realistic. It showed you the creativity of the writers',
               'This movie I could only watch for 5 minutes it was too unbearable. Dont waste your money or a minute of your life.',
               'I love how far hollwood has come in its realistic depicitions. Great movie and example',
               'I hate how fake hollywood has become after seeing that movie.',
               'Thats it they lost thier edge and went down the drain 5 years ago with making quality films.',
               'I dont know why alot of people are complaining that movie was original.']
new_seq = tokenizer.texts_to_sequences(review_pred)
padded=pad_sequences(new_seq, maxlen=max_length,truncating=trunc_type)
output=model.predict(padded)
for i in range(0,len(review_pred)):
    print('Review:'+review_pred[i]+''+'sentiment:'+str(output[i])+'\n')

model.save('sentiment_pred.h5')